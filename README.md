# WebCopy

Ferramenta CLI em Python para fazer cÃ³pias organizadas e estruturadas de pÃ¡ginas web. Baixa uma pÃ¡gina HTML e todos os seus assets (CSS, JavaScript, imagens, fontes), organizando-os em uma estrutura de pastas padronizada que funciona localmente como um site estÃ¡tico completo.

## ğŸ¯ Objetivo

Criar cÃ³pias fiÃ©is de pÃ¡ginas web que rodem localmente em HTML+CSS+JS, com todos os assets minimamente organizados em pastas como um projeto padrÃ£o.

## âš™ï¸ Arquitetura

O projeto Ã© estruturado em mÃ³dulos Python com responsabilidades bem definidas:

```
WebCopy/
â”œâ”€â”€ src/webcopy/
â”‚   â”œâ”€â”€ cli.py          # Interface CLI com click
â”‚   â”œâ”€â”€ downloader.py   # Download HTTP com retry e suporte a Brotli
â”‚   â”œâ”€â”€ parser.py       # Parse HTML/CSS e extraÃ§Ã£o de URLs
â”‚   â””â”€â”€ organizer.py    # OrganizaÃ§Ã£o de arquivos e reescrita de URLs
â”œâ”€â”€ output/             # Sites baixados (ignorado no git)
â”œâ”€â”€ requirements.txt    # DependÃªncias
â””â”€â”€ setup.py           # ConfiguraÃ§Ã£o de instalaÃ§Ã£o
```

### Fluxo de ExecuÃ§Ã£o

1. **Download**: Baixa HTML principal via requests
2. **Parse**: BeautifulSoup4 extrai URLs de assets (CSS, JS, imagens, fontes)
3. **Parse CSS**: Extrai URLs de dentro de arquivos CSS (`url()`)
4. **Download Assets**: Baixa cada asset sequencialmente
5. **OrganizaÃ§Ã£o**: Salva arquivos em estrutura organizada por tipo
6. **Reescrita**: Reescreve URLs no HTML e CSS para caminhos locais
7. **SaÃ­da**: Gera site funcional em `output/dominio_timestamp/`

## ğŸ“¦ InstalaÃ§Ã£o

```bash
# Entre no diretÃ³rio do projeto
cd WebCopy

# Instale as dependÃªncias
pip install -r requirements.txt

# Instale o pacote em modo de desenvolvimento
pip install -e .

# OU use o script de instalaÃ§Ã£o:
# Windows: install.bat
# Linux/Mac: bash install.sh
```

**Nota Importante**: Se vocÃª receber o erro "No module named webcopy", certifique-se de executar `pip install -e .` na raiz do projeto (nÃ£o dentro da pasta `src`).

## ğŸš€ Uso

### Interface Web (Recomendado) ğŸŒ

A forma mais fÃ¡cil de usar o WebCopy Ã© atravÃ©s da interface web:

```bash
# Inicie o servidor web
python run_web.py

# Acesse no navegador
# http://localhost:5000
```

Depois Ã© sÃ³ inserir a URL, acompanhar o progresso e baixar o resultado!

ğŸ“– **[DocumentaÃ§Ã£o completa da Interface Web](WEB_INTERFACE.md)**

### Linha de Comando (CLI)

```bash
# Uso bÃ¡sico - baixa a pÃ¡gina e cria diretÃ³rio com timestamp
webcopy https://example.com

# Especificar nome de saÃ­da customizado
webcopy https://example.com --output meu-site

# Especificar diretÃ³rio base diferente
webcopy https://example.com --output-dir meus-sites

# Ou usando Python diretamente
python -m webcopy https://example.com
```

### Exemplo Real

```bash
$ python -m webcopy https://the7.io/fse-crypto/

[WebCopy] Iniciando copia de: https://the7.io/fse-crypto/
[+] Baixando pagina principal...
[+] Analisando pagina e extraindo assets...
    Encontrados: 9 CSS, 7 JS, 123 imagens, 0 fontes, 1 outros
[+] Baixando arquivos CSS...
[+] Baixando arquivos JavaScript...
[+] Baixando imagens...
[+] Baixando outros recursos...
[+] Reescrevendo URLs no HTML...
[+] Reescrevendo URLs nos arquivos CSS...

[OK] Copia concluida com sucesso!
[>] Arquivos salvos em: output/the7.io_2026-01-31_12-30-45

Para visualizar, abra o arquivo index.html no navegador.
```

## ğŸ“ Estrutura de SaÃ­da

Cada site baixado serÃ¡ organizado assim:

```
output/
â””â”€â”€ example.com_2026-01-31_12-30-45/
    â”œâ”€â”€ index.html          # HTML principal (com URLs reescritas)
    â”œâ”€â”€ css/               # Todos os arquivos CSS
    â”‚   â”œâ”€â”€ style.css
    â”‚   â””â”€â”€ main.css
    â”œâ”€â”€ js/                # Todos os arquivos JavaScript
    â”‚   â”œâ”€â”€ app.js
    â”‚   â””â”€â”€ vendor.js
    â”œâ”€â”€ images/            # Imagens (jpg, png, gif, svg, webp)
    â”‚   â”œâ”€â”€ logo.svg
    â”‚   â””â”€â”€ hero.webp
    â”œâ”€â”€ fonts/             # Fontes web (woff, woff2, ttf, otf)
    â”‚   â””â”€â”€ custom-font.woff2
    â””â”€â”€ assets/            # Outros recursos (favicon, etc)
        â””â”€â”€ favicon.ico
```

## âœ¨ Recursos

### Interface & Usabilidade
- âœ… **Interface Web moderna e amigÃ¡vel** (Flask + HTML/CSS/JS)
- âœ… **Progresso em tempo real** com status detalhado
- âœ… **Download em ZIP** do site completo
- âœ… **Preview no navegador** antes de baixar
- âœ… Interface CLI completa (click)

### Funcionalidades Core
- âœ… Download de HTML e todos os assets referenciados
- âœ… OrganizaÃ§Ã£o automÃ¡tica por tipo de arquivo (CSS, JS, images, fonts, assets)
- âœ… Reescrita inteligente de URLs para funcionamento local
- âœ… Suporte a recursos de CDNs externos (baixa e hospeda localmente)
- âœ… Tratamento de URLs relativas e absolutas
- âœ… Suporte a compressÃ£o Brotli (br) e Gzip
- âœ… ExtraÃ§Ã£o de assets dentro de arquivos CSS (`url()`, `@font-face`)
- âœ… Retry automÃ¡tico em caso de falhas de rede
- âœ… Parser HTML resiliente (html.parser nativo do Python)
- âœ… Nomes de arquivo Ãºnicos para evitar colisÃµes

## ğŸ”§ Detalhes TÃ©cnicos

### Gerenciamento de CompressÃ£o

O projeto suporta automaticamente:
- **Gzip** (padrÃ£o do requests)
- **Brotli** (requer `brotli` instalado)

Sites modernos como [the7.io](https://the7.io/fse-crypto/) usam compressÃ£o Brotli (`Content-Encoding: br`). A biblioteca `brotli` Ã© essencial para descomprimir esse conteÃºdo corretamente.

### Reescrita de URLs

O sistema mantÃ©m um dicionÃ¡rio mapeando URLs originais para caminhos locais:

```python
{
  'https://example.com/style.css': 'css/style.css',
  'https://cdn.example.com/app.js': 'js/app.js',
  '/images/logo.png': 'images/logo.png'
}
```

Todas as referÃªncias no HTML e CSS sÃ£o reescritas para usar esses caminhos locais.

### OrganizaÃ§Ã£o de Arquivos

- **CSS**: Identificado por extensÃ£o `.css` e Content-Type
- **JavaScript**: ExtensÃ£o `.js` e tags `<script>`
- **Imagens**: ExtensÃµes `.jpg`, `.png`, `.gif`, `.svg`, `.webp`, etc.
- **Fontes**: ExtensÃµes `.woff`, `.woff2`, `.ttf`, `.otf`, `.eot`
- **Outros**: Favicons, manifestos, e recursos diversos

### Parser HTML

Usa `html.parser` (nativo do Python) em vez de `lxml` para:
- Melhor preservaÃ§Ã£o do HTML original
- Menos problemas de encoding
- Funciona sem dependÃªncias C compiladas

## âš ï¸ LimitaÃ§Ãµes

- Apenas baixa a pÃ¡gina especificada (nÃ£o faz crawling de links internos)
- NÃ£o suporta SPAs (Single Page Applications) com conteÃºdo carregado via JavaScript
- NÃ£o processa JavaScript que carrega assets dinamicamente (fetch, XHR)
- Recursos que requerem autenticaÃ§Ã£o nÃ£o serÃ£o baixados
- Sites com proteÃ§Ã£o anti-bot agressiva podem bloquear o acesso
- JavaScript inline e eventos podem nÃ£o funcionar corretamente offline

## ğŸ› SoluÃ§Ã£o de Problemas

### "No module named webcopy"

**Causa**: O pacote nÃ£o estÃ¡ instalado ou foi instalado em um ambiente Python diferente.

**SoluÃ§Ã£o**:
```bash
# Certifique-se de estar na raiz do projeto
cd WebCopy

# Instale em modo de desenvolvimento
pip install -e .

# Ou reinstale
pip uninstall webcopy -y && pip install -e .
```

### HTML com caracteres estranhos/corrompidos

**Causa**: Site usa compressÃ£o Brotli sem a biblioteca `brotli` instalada.

**SoluÃ§Ã£o**:
```bash
pip install brotli
```

ApÃ³s instalar, execute o webcopy novamente. O HTML serÃ¡ decodificado corretamente.

### Assets nÃ£o sÃ£o baixados

**Causa Comum**: 
1. URLs relativas nÃ£o resolvidas corretamente
2. Assets protegidos por CORS ou autenticaÃ§Ã£o
3. URLs dinÃ¢micas geradas por JavaScript

**VerificaÃ§Ã£o**:
- Confira os avisos `[!]` no console durante o download
- Assets de CDNs externos podem ter rate limiting

### Site nÃ£o funciona localmente

**PossÃ­veis causas**:
1. JavaScript requer servidor (APIs, fetch, etc.)
2. Recursos bloqueados por CORS no browser
3. Service Workers tentando fazer cache

**Dica**: Abra com um servidor local simples:
```bash
cd output/site-baixado
python -m http.server 8000
# Acesse http://localhost:8000
```

## ğŸ“š DependÃªncias

- **Python 3.8+** - Linguagem base
- **requests** (>=2.31.0) - RequisiÃ§Ãµes HTTP com retry e sessÃµes
- **beautifulsoup4** (>=4.12.0) - Parse de HTML e extraÃ§Ã£o de elementos
- **lxml** (>=5.0.0) - Parser XML/HTML performÃ¡tico
- **click** (>=8.1.0) - Interface CLI amigÃ¡vel
- **brotli** (>=1.0.0) - Suporte a compressÃ£o Brotli (essencial!)
- **flask** (>=3.0.0) - Interface web
- **flask-cors** (>=4.0.0) - CORS para desenvolvimento web

## ğŸ”® Melhorias Futuras

### âœ… Recentemente Implementadas
- âœ… Interface web com Flask (Janeiro 2026)
- âœ… Progresso em tempo real via polling
- âœ… Download em ZIP
- âœ… Preview no navegador

### NÃ£o Implementadas (Escopo BÃ¡sico)
- [ ] Crawling de mÃºltiplas pÃ¡ginas
- [ ] Download paralelo (threading/async)
- [ ] MinificaÃ§Ã£o de assets
- [ ] Suporte para SPAs (Selenium/Playwright)
- [ ] Versionamento de sites

### Melhorias na Interface Web
- [ ] WebSockets para progresso (substituir polling)
- [ ] PersistÃªncia de jobs em banco de dados
- [ ] HistÃ³rico de downloads
- [ ] AutenticaÃ§Ã£o de usuÃ¡rios
- [ ] Cancelamento de jobs em andamento

### ImplementaÃ§Ãµes PossÃ­veis
- [ ] Modo verboso com mais detalhes de debug
- [ ] Blacklist/whitelist de domÃ­nios
- [ ] Limite de tamanho de arquivo
- [ ] EstatÃ­sticas de download (tempo, tamanho, etc.)
- [ ] ConfiguraÃ§Ã£o via arquivo (config.yaml)

## ğŸ¤ Contexto para IAs

Este projeto foi desenvolvido para criar cÃ³pias organizadas de pÃ¡ginas web para uso offline. A principal descoberta durante o desenvolvimento foi a necessidade de suporte a **compressÃ£o Brotli**, que sites modernos usam extensivamente.

### DecisÃµes de Design

1. **html.parser vs lxml**: Escolhido html.parser para evitar problemas de encoding
2. **Download sequencial**: Simplicidade sobre performance (evita rate limiting)
3. **Estrutura fixa**: Pastas padronizadas facilitam navegaÃ§Ã£o
4. **Sem crawling**: MantÃ©m escopo controlado e previsÃ­vel
5. **Reescrita completa**: Garante funcionamento offline sem dependÃªncias externas

### Problemas Resolvidos

1. **Brotli Compression**: Sites modernos (Cloudflare, WordPress) usam Brotli
2. **URLs relativas**: ConversÃ£o correta usando `urllib.parse.urljoin`
3. **Assets em CSS**: Parser recursivo extrai `url()` e `@font-face`
4. **Encoding**: UTF-8 com fallback para apparent_encoding
5. **ColisÃ£o de nomes**: Sistema de nomes Ãºnicos por hash ou contador

## ğŸ“„ LicenÃ§a

MIT License - Sinta-se livre para usar, modificar e distribuir.

## ğŸ‘¨â€ğŸ’» Desenvolvimento

Desenvolvido em Janeiro de 2026 como ferramenta para preservaÃ§Ã£o de conteÃºdo web e estudo offline.
